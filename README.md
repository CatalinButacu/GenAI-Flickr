# Physics-Constrained Video Generation

Dissertation project â€” generate physics-realistic videos from text prompts.

## Quick Start

```bash
pip install -r requirements.txt
python main.py "a red ball falls onto a blue cube"
```

## Pipeline

```
Text Prompt
    â†“ M1  Scene Understanding  â€” parse entities, actions, spatial relations
    â†“ M2  Scene Planner        â€” place entities in 3-D world space
    â†“ M3  Asset Generator      â€” Shap-E 3-D mesh generation    (optional)
    â†“ M4  Motion Generator     â€” SSM / KIT-ML motion clips     (optional)
    â†“ M5  Physics Engine       â€” PyBullet simulation + camera
    â†“ M6  RL Controller        â€” PPO humanoid control          (stub)
    â†“ M7  Render Engine        â€” post-processing               (stub)
    â†“ M8  AI Enhancer          â€” ControlNet frame enhancement  (optional)
    â†“ MP4 Video
```

## Usage

```bash
# Default
python main.py "a red ball falls onto a blue cube"

# Custom duration / fps
python main.py "a person walks and kicks a ball" --duration 8 --fps 30

# Enable 3-D mesh generation (requires ~4 GB GPU)
python main.py "a wooden chair tips over" --with-assets

# Enable ControlNet enhancement (requires ~8 GB GPU)
python main.py "a sphere bounces" --with-enhance

# Disable motion generation (faster)
python main.py "boxes collide" --no-motion

python main.py --help
```

## Python API

```python
from src.pipeline import Pipeline, PipelineConfig

config   = PipelineConfig(duration=8, fps=30)
pipeline = Pipeline(config)
result   = pipeline.run("A person walks to a ball and kicks it")
print(result["video_path"])   # outputs/videos/output.mp4
```

## Module Reference

| # | Module | Status | Key files |
|---|--------|--------|-----------|
| M1 | Scene Understanding | âœ… Active | `prompt_parser.py`, `orchestrator.py` |
| M2 | Scene Planner | âœ… Active | `planner.py` |
| M3 | Asset Generator | âš¡ Optional | `generator.py` (Shap-E) |
| M4 | Motion Generator | âš¡ Optional | `generator.py` (SSM / KIT-ML) |
| M5 | Physics Engine | âœ… Active | `scene.py`, `simulator.py` |
| M6 | RL Controller | ðŸ”§ Stub | `controller.py` (PPO planned) |
| M7 | Render Engine | ðŸ”§ Stub | `render_engine.py` (post-proc planned) |
| M8 | AI Enhancer | âš¡ Optional | `renderer.py` (ControlNet) |

## Project Structure

```
main.py                        # Single entry point
src/
â”œâ”€â”€ pipeline.py                # Pipeline orchestrator
â”œâ”€â”€ shared/
â”‚   â””â”€â”€ vocabulary.py          # Canonical objects, actions, properties
â””â”€â”€ modules/
    â”œâ”€â”€ scene_understanding/ # M1: Text â†’ ParsedScene
    â”‚   â”œâ”€â”€ prompt_parser.py   #   Rules-based parser (fast, no GPU)
    â”‚   â””â”€â”€ orchestrator.py    #   T5 ML parser (StoryAgent)
    â”œâ”€â”€ scene_planner/       # M2: ParsedScene â†’ PlannedScene
    â”œâ”€â”€ asset_generator/     # M3: entity â†’ 3-D mesh (optional)
    â”œâ”€â”€ motion_generator/    # M4: action text â†’ motion clip (optional)
    â”œâ”€â”€ physics_engine/      # M5: PlannedScene â†’ frames + video
    â”œâ”€â”€ m6_rl_controller/       # M6: PPO control (stub)
    â”œâ”€â”€ render_engine/       # M7: post-processing (stub)
    â””â”€â”€ ai_enhancer/         # M8: ControlNet enhance (optional)
config/
â””â”€â”€ default.yaml               # Physics / camera / output defaults
scripts/                       # Training utilities (M1 T5, M4 SSM)
tests/                         # Benchmark suites per module
examples/                      # Standalone demo scripts
```

## M1: Two parser modes

| Mode | Class | Speed | Accuracy |
|------|-------|-------|----------|
| Rules (default) | `PromptParser` | Fast, no GPU | Good for common objects/actions |
| ML (T5 seq2seq) | `StoryAgent` | Slow, requires checkpoint | Higher accuracy |

Train the T5 extractor:
```bash
python scripts/train_m1_t5.py
```

## Requirements

- Python 3.10+
- CUDA GPU for M3 (Shap-E) and M8 (ControlNet)
- CPU-only sufficient for M1 (rules), M2, M5

## License

MIT
